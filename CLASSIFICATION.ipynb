{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkMoSEi6QsP0B4ImxDIqBH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pankosmas/TopicExtractor/blob/main/CLASSIFICATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLASSIFICATIOn"
      ],
      "metadata": {
        "id": "-dYJn0OShEu9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADPRszfrhD6C"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"C:\\\\Python\\\\torchidis\\\\procNERbala.csv\")\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download el_core_news_lg\n",
        "!pip install Unidecode\n",
        "import spacy\n",
        "from difflib import SequenceMatcher\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import math\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "import re\n",
        "nlp = spacy.load(\"el_core_news_lg\")"
      ],
      "metadata": {
        "id": "ob7zUuUahGmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stoplist = set('αλλα αλλά εγω εγώ εσυ εσύ αυτος αυτός αυτη αυτή αυτο αυτό εμεις εμείς εσεις εσείς αυτοι αυτοί αυτα '\n",
        "               'αυτά το του τα των τις τους τοις και ναι οχι μη μην δε λίγο λιγο τόσο τοσο γι για δεν ειμαι είμαι '\n",
        "               'εισαι είσαι ειναι είναι ειμαστε είμαστε ειστε είστε ειναι είναι ουτε ούτε μητε μήτε ουδε ουδέ η ή '\n",
        "               'ειτε είτε αν και μα παρα πάρα παρά ομως όμως ωστοσο ωστόσο ενω ενώ μολονοτι μολονότι μονο μόνο μονό '\n",
        "               'που λοιπον λοιπόν ωστε ώστε αρα άρα επομενως επομένως οποτε όποτε οπότε δηλαδη δηλαδή οτι ότι πως που '\n",
        "               'μην μηπως μήπως να αμα άμα οταν όταν καθως καθώς αφου αφού αφοτου αφότου πριν μολις προτου ωσπου '\n",
        "               'ωσοτου σαν γιατι διοτι επειδη αφου τι οτι για να ωστε ως παρα αναμεσα κάνω κάνεις κάνει κάνουν '\n",
        "               'κάνουμε κι δε μέρα μεταξυ εαν ανω κατω πανω πισω μπρος μπροστα εχω κανω λεω βλεπω μπορω μπορει ισως '\n",
        "               'καλα καλο καλος καλη καλων έχω έχεις έχει έχουμε έχετε έχουν εχω εχεις εχει εχουμε εχετε εχουν'\n",
        "               'είχα είχες είχε είχαμε είχατε είχαν ειχα ειχες ειχε ειχαμε ειχατε ειχαν καλους καλε εκει εκτος εντος'\n",
        "               'μεσα εξω ιδιο ηταν ζωη ολα ολο ολος ολοι ομως ποτε σπανια οποιος οποια οποιο οποιους οποιοι οποιες πολυ πολλα πολλη πολλων πολλους τωρα χθες σημερα '\n",
        "               'αυριο παρον παρων μελλον παρελθον χθες ωρα χωρις με χρονια πρωτος της κατα στα στο στη στων στις στους '\n",
        "               'οι ο η απο στην στη στον στο τον την μόλις προτού ώσπου ωσότου σαν γιατί διότι επειδή αφού τι ότι για '\n",
        "               'να ώστε ως πάρα αναμεσά έχετε κάνετε χθες χτες εχτές εχθές μεταξύ εάν άνω κάτω πάνω πίσω μπρος μπροστά '\n",
        "               'έχω κάνω λέω βλέπω μπορώ μπορεί ίσως καλά καλό καλός καλή καλών καλούς καλέ εκεί εκτός εντός μέσα έξω '\n",
        "               'ίδιο ήταν ζωή μεγάλη μικρή όλα όλο όλος όλοι όμως ποτέ σπάνια όποιος όποια όποιο όποιους όποιοι όποιες '\n",
        "               'πολύ πολλά πολλή πολλών πολλούς τώρα χθες σήμερα αύριο παρόν παρών μέλλον παρελθόν χθες ώρα χωρίς με '\n",
        "               'χρονιά πρώτος της κατά στα στο μετα μετά όσων οσων στη στων στις στους οι ο η από στην στη στον στο τον την θα όμως σε '\n",
        "               'αυτού τη όλους μας σας πρέπει ήδη έχει είχε μια μία ένα ένας ενός υπό οποία οποίο οποίος οποίους δικό '\n",
        "               'μετά κοντά έως εώς άλλους κάτι γύρω πιο όσο έχουν μπορώ μπορεί μπορείτε μπορούν πάνε κάντε δικό θέλετε '\n",
        "               'δώσετε προς όπως δώστε δει δείτε βλέπω έτσι άλλοι ίδια νέα πολλά κυρίως άλλη ακόμα οποίων επί είπε όχι '\n",
        "               'μέχρι μου σου του δυο δύο πλέον είπε α β γ δ ε ζ η θ ι κ λ μ ν ξ ο π ρ σ τ υ φ χ ψ ω αυτ όλη όσους '\n",
        "               'όλες αυτούς θέλω βάζω κάθε κά τότε έχουμε θέλει έκανε βρίσκεται ακόμη όπου φέτος πέρσι μετά πέρυσι '\n",
        "               'πήρε έδωσε ης βγει νέος νέα νέοι νέους νέας νέων ος γίνει υπάρχει υπάρχω υπάρχουν πάλι θέμα πώς μια μία μιας'\n",
        "               'ανεξαρτήτως ίδιος μάλιστα έναν έγινε άλλο τρία τρια τρείς τρεις πέντε έξι επτά οκτώ δέκα τέσσερις θεμα'\n",
        "               'ετ κεδ εναντίον τέσσερα αε ίδιες σ ς εννέα εννιά αο γς τέλος πάντως επίσης ας πχ x εκ περί αυτές άλλων'.split(' '))\n",
        "s2 = set([word.upper() for word in stoplist])\n",
        "s3 = set([word.capitalize() for word in stoplist])\n",
        "stoplist = stoplist.union(s2)\n",
        "stoplist = stoplist.union(s3)"
      ],
      "metadata": {
        "id": "Ee0gYGKDhQb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(text):\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = text.replace('\\xa0', ' ')\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    \n",
        "    doc = nlp(text)\n",
        "    clean_text = [token.text for token in doc if token.pos_ in [\"NOUN\", \"VERB\"]]\n",
        "\n",
        "    text = ' '.join(clean_text)\n",
        "    \n",
        "    return text"
      ],
      "metadata": {
        "id": "Mq5JyNcMjpei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(text):\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = text.replace('\\xa0', ' ')\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    words = [word for word in text.split(\" \") if word not in stoplist]\n",
        "    text = ' '.join(words)\n",
        "    '''\n",
        "    doc = nlp(text)\n",
        "    clean_text = [token.text for token in doc if token.pos_ in [\"NOUN\", \"ADJ\", \"VERB\"]]\n",
        "\n",
        "    text = ' '.join(clean_text)\n",
        "    '''\n",
        "    return text"
      ],
      "metadata": {
        "id": "57XPZQldhRuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "categories = ['Κοινωνία', 'Οικονομία', 'Κόσμος', 'Τεχνολογία', 'Πολιτική', 'Υγεία', 'Περιβάλλον', 'Πολιτισμός', 'Δικαιοσύνη', 'Εκπαίδευση', 'Αστυνομικό']\n",
        "sum = len(data[data['category']=='Αθλητισμός'])\n",
        "nn = data\n",
        "for ctg in categories:\n",
        "  df = data[data['category']==ctg]\n",
        "  subsum = len(df)\n",
        "  d = math.floor(sum / subsum)\n",
        "  print(d)\n",
        "  u = sum % subsum\n",
        "  for i in range(d-1):\n",
        "    nn = pd.concat([nn, df])\n",
        "\n",
        "  df2 = df.head(u)\n",
        "  nn = pd.concat([nn, df2])\n",
        "\n",
        "len(nn)"
      ],
      "metadata": {
        "id": "uyFtnRSuhVVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "chart = sns.countplot(df.category)\n",
        "chart.set_xticklabels(chart.get_xticklabels(), rotation=45)"
      ],
      "metadata": {
        "id": "WSM3DBf_hWhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "df['category_target'] = label_encoder.fit_transform(df['category'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "5msfDEuzhX7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfp = df['pars_ner'].dropna()"
      ],
      "metadata": {
        "id": "Ey2YYKrCiJGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAIN TEST SPLIt"
      ],
      "metadata": {
        "id": "xIg_dPiljX4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dfp['pars_ner'], \n",
        "                                                    dfp['category_target'], \n",
        "                                                    test_size = 0.2, \n",
        "                                                    random_state=8)"
      ],
      "metadata": {
        "id": "qIB8XzrHhZIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFIDF"
      ],
      "metadata": {
        "id": "-aESZyIXjaGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_range = (1,3)\n",
        "min_df = 5\n",
        "max_df = 1.\n",
        "max_features = 300\n",
        "tfidf = TfidfVectorizer(encoding='utf-8',\n",
        "                       ngram_range=ngram_range,\n",
        "                       stop_words=None,\n",
        "                       lowercase=False,\n",
        "                       max_df=max_df,\n",
        "                       min_df=min_df,\n",
        "                       max_features=max_features,\n",
        "                       norm='l2',\n",
        "                       sublinear_tf = True)\n",
        "\n",
        "features_train = tfidf.fit_transform(x_train).toarray()\n",
        "labels_train = y_train\n",
        "\n",
        "features_test = tfidf.transform(x_test).toarray()\n",
        "labels_test = y_test"
      ],
      "metadata": {
        "id": "N6_SuzOYhpf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RANDOM FOREST"
      ],
      "metadata": {
        "id": "La7KFVOCjUEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "n_estimators = [100, 300, 500, 800, 1200]\n",
        "max_depth = [5, 8, 15, 25, 30]\n",
        "min_samples_split = [2, 5, 10, 15, 100]\n",
        "min_samples_leaf = [1, 2, 5, 10]\n",
        "\n",
        "hyperF = dict(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "model = RandomForestClassifier()\n",
        "gridF = GridSearchCV(model, hyperF, cv=3, verbose=1, n_jobs=-1)\n",
        "bestF = gridF.fit(features_train, labels_train)\n",
        "bestF.best_params_"
      ],
      "metadata": {
        "id": "YB9DhtcyjO-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(random_state=1, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1200)\n",
        "model.fit(features_train, labels_train)\n",
        "model_predictions = model.predict(features_test)\n",
        "print('Accuracy', accuracy_score(labels_test, model_predictions))\n",
        "print(classification_report(labels_test, model_predictions))"
      ],
      "metadata": {
        "id": "ROGmUbHfjjie"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}